{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe9ZX3DRqKLb"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Oct 11 01:41:03 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4gboGGxqKLd"
      },
      "outputs": [],
      "source": [
        "@author: dima\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujvZHvZEqMe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyvPE_smqKLe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix23To7MqKLe"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwxXfSDjqKLg"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlPc4IuyqKLg"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPgWTwdpqKLh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRLVudURqKLi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as tf_keras_backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9cRJtCMqKLj"
      },
      "outputs": [],
      "source": [
        "tf_keras_backend.set_image_data_format('channels_last')\n",
        "tf_keras_backend.image_data_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5dI3GD1qKLk"
      },
      "outputs": [],
      "source": [
        "with open('./words.txt') as f:\n",
        "    contents = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n904ljY-qKLk"
      },
      "outputs": [],
      "source": [
        "lines = [line.strip() for line in contents]\n",
        "lines = lines[18:100]\n",
        "lines[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIc6TLs6qKLk"
      },
      "outputs": [],
      "source": [
        "max_label_len = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wRdM79cqKLl"
      },
      "outputs": [],
      "source": [
        "char_list = \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE-yHDjFqKLl"
      },
      "source": [
        "string.ascii_letters + string.digits (Chars & Digits)<br>\n",
        "or <br>\n",
        "\"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c2B9iz4qKLl"
      },
      "outputs": [],
      "source": [
        "print(char_list, len(char_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOy4G8GwqKLm"
      },
      "outputs": [],
      "source": [
        "def encode_to_labels(txt):\n",
        "    # encoding each output word into digits\n",
        "    dig_lst = []\n",
        "    for index, chara in enumerate(txt):\n",
        "        dig_lst.append(char_list.index(chara))\n",
        "\n",
        "    return dig_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljgs3rI7qKLm"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0xZ5VggqKLm"
      },
      "outputs": [],
      "source": [
        "RECORDS_COUNT = 10000\n",
        "train_images = []\n",
        "train_labels = []\n",
        "train_input_length = []\n",
        "train_label_length = []\n",
        "train_original_text = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnen6xn_qKLn"
      },
      "outputs": [],
      "source": [
        "valid_images = []\n",
        "valid_labels = []\n",
        "valid_input_length = []\n",
        "valid_label_length = []\n",
        "valid_original_text = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMZgCNd0qKLn"
      },
      "outputs": [],
      "source": [
        "inputs_length = []\n",
        "labels_length = []\n",
        "def process_image(img):\n",
        "    \"\"\"\n",
        "    Converts image to shape (32, 128, 1) & normalize\n",
        "    \"\"\"\n",
        "    w, h = img.shape\n",
        "\n",
        "    # Aspect Ratio Calculation\n",
        "    new_w = 32\n",
        "    new_h = int(h * (new_w / w))\n",
        "    img = cv2.resize(img, (new_h, new_w))\n",
        "    w, h = img.shape\n",
        "\n",
        "    img = img.astype('float32')\n",
        "\n",
        "    # Converts each to (32, 128, 1)\n",
        "    if w < 32:\n",
        "        add_zeros = np.full((32-w, h), 255)\n",
        "        img = np.concatenate((img, add_zeros))\n",
        "        w, h = img.shape\n",
        "\n",
        "    if h < 128:\n",
        "        add_zeros = np.full((w, 128-h), 255)\n",
        "        img = np.concatenate((img, add_zeros), axis=1)\n",
        "        w, h = img.shape\n",
        "\n",
        "    if h > 128 or w > 32:\n",
        "        dim = (128,32)\n",
        "        img = cv2.resize(img, dim)\n",
        "\n",
        "    img = cv2.subtract(255, img)\n",
        "\n",
        "    img = np.expand_dims(img, axis=2)\n",
        "\n",
        "    # Normalize\n",
        "    img = img / 255\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac4Knu1MqKLo"
      },
      "outputs": [],
      "source": [
        "for index, line in enumerate(lines):\n",
        "    splits = line.split(' ')\n",
        "    status = splits[1]\n",
        "\n",
        "    if status == 'ok':\n",
        "        word_id = splits[0]\n",
        "        word = \"\".join(splits[8:])\n",
        "\n",
        "        splits_id = word_id.split('-')\n",
        "        filepath = 'words/{}/{}-{}/{}.png'.format(splits_id[0],\n",
        "                                                  splits_id[0],\n",
        "                                                  splits_id[1],\n",
        "                                                  word_id)\n",
        "\n",
        "        # process image\n",
        "        img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "        try:\n",
        "            img = process_image(img)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        # process label\n",
        "        try:\n",
        "            label = encode_to_labels(word)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        if index % 10 == 0:\n",
        "            valid_images.append(img)\n",
        "            valid_labels.append(label)\n",
        "            valid_input_length.append(31)\n",
        "            valid_label_length.append(len(word))\n",
        "            valid_original_text.append(word)\n",
        "        else:\n",
        "            train_images.append(img)\n",
        "            train_labels.append(label)\n",
        "            train_input_length.append(31)\n",
        "            train_label_length.append(len(word))\n",
        "            train_original_text.append(word)\n",
        "\n",
        "        if len(word) > max_label_len:\n",
        "            max_label_len = len(word)\n",
        "\n",
        "    if index >= RECORDS_COUNT:\n",
        "        break\n",
        "train_padded_label = pad_sequences(train_labels,\n",
        "                             maxlen=max_label_len,\n",
        "                             padding='post',\n",
        "                             value=len(char_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nad2hjbyqKLo"
      },
      "outputs": [],
      "source": [
        "valid_padded_label = pad_sequences(valid_labels,\n",
        "                             maxlen=max_label_len,\n",
        "                             padding='post',\n",
        "                             value=len(char_list))\n",
        "train_padded_label.shape, valid_padded_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl3HrUv2qKLp"
      },
      "outputs": [],
      "source": [
        "train_images = np.asarray(train_images)\n",
        "train_input_length = np.asarray(train_input_length)\n",
        "train_label_length = np.asarray(train_label_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHZedXP-qKLp"
      },
      "outputs": [],
      "source": [
        "valid_images = np.asarray(valid_images)\n",
        "valid_input_length = np.asarray(valid_input_length)\n",
        "valid_label_length = np.asarray(valid_label_length)\n",
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqnL4zakqKLp"
      },
      "outputs": [],
      "source": [
        "def Model1():\n",
        "    # input with shape of height=32 and width=128\n",
        "    inputs = Input(shape=(32,128,1))\n",
        "\n",
        "    # convolution layer with kernel size (3,3)\n",
        "    conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
        "    # poolig layer with kernel size (2,2)\n",
        "    pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        "\n",
        "    conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
        "    pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        "\n",
        "    conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
        "\n",
        "    conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
        "    # poolig layer with kernel size (2,1)\n",
        "    pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        "\n",
        "    conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
        "    # Batch normalization layer\n",
        "    batch_norm_5 = BatchNormalization()(conv_5)\n",
        "\n",
        "    conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
        "    batch_norm_6 = BatchNormalization()(conv_6)\n",
        "    pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        "\n",
        "    conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
        "\n",
        "    # squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        "    reshape = Reshape((31, 512))(conv_7)\n",
        "\n",
        "\n",
        "    # bidirectional LSTM layers with units=128\n",
        "    # blstm_1 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.2))(squeezed\n",
        "    blstm_1 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.2))(reshape)\n",
        "    blstm_2 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.2))(blstm_1)\n",
        "\n",
        "    outputs = Dense(len(char_list)+1, activation = 'softmax', name='predictions')(blstm_2)\n",
        "\n",
        "    # model to be used at test time\n",
        "    act_model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return act_model,outputs,inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTM5ye5PqKLq"
      },
      "outputs": [],
      "source": [
        "model,outputs,inputs=Model1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xTlj55iqKLq"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go_QYhOMqKLq"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "epochs = 60\n",
        "e = str(epochs)\n",
        "optimizer_name = 'adam'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiAJDwoTqKLq"
      },
      "outputs": [],
      "source": [
        "def my_ctc_loss(labels, y_pred, input_length, label_length):\n",
        "    # y_pred, labels, input_length, label_length = args\n",
        "\n",
        "    return tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-iPMXsKqKLr"
      },
      "source": [
        "optimizer = Adam(learning_rate=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBnFAv3VqKLr"
      },
      "source": [
        "epochs = 10<br>\n",
        "for epoch in range(epochs):<br>\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqhKbop0qKLr"
      },
      "source": [
        "    # Iterate over the batches of the dataset.<br>\n",
        "    # for step, train_batch in enumerate(train_dataset_batched):<br>\n",
        "    for i in range(len(train_images) - 1):<br>\n",
        "        step = i<br>\n",
        "        # x_train = train_images_batched[i]<br>\n",
        "        # x_train_lengths = train_input_length_batched[i]<br>\n",
        "        # y_train = train_padded_label_batched[i]<br>\n",
        "        # y_train_lengths = train_label_length_batched[i]<br>\n",
        "        x_train = train_images[i]<br>\n",
        "        x_train_lengths = train_input_length[i]<br>\n",
        "        y_train = train_padded_label[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBAAERXqqKLs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#         # x_train = np.insert(x_train, 0, y_train)\n",
        "#         x_train = (y_train, x_train)\n",
        "#         y_train_lengths = train_label_length[i]\n",
        "#         # Open a GradientTape to record the operations run\n",
        "#         # during the forward pass, which enables auto-differentiation.\n",
        "#         with tf.GradientTape() as tape:\n",
        "#             # Run the forward pass of the layer.\n",
        "#             # The operations that the layer applies\n",
        "#             # to its inputs are going to be recorded\n",
        "#             # on the GradientTape.\n",
        "#             logits = model(x_train, training=True)  # Logits for this minibatch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rM_RvT1qKLs"
      },
      "source": [
        "            # Compute the loss value for this minibatch.<br>\n",
        "            # loss_value = loss_fn(y_batch_train, logits)<br>\n",
        "            loss_value = my_ctc_loss(y_train, logits, x_train_lengths, y_train_lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ20fXqdqKLs"
      },
      "source": [
        "        # Use the gradient tape to automatically retrieve<br>\n",
        "        # the gradients of the trainable variables with respect to the loss.<br>\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eD3FFjMqKLt"
      },
      "source": [
        "        # Run one step of gradient descent by updating<br>\n",
        "        # the value of the variables to minimize the loss.<br>\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8rZM9iNqKLt"
      },
      "source": [
        "        # Log every 200 batches.<br>\n",
        "        # if step % 1 == 0:<br>\n",
        "        print(<br>\n",
        "            \"Training loss (for one batch) at step %d: %.4f\"<br>\n",
        "            % (step, float(loss_value))<br>\n",
        "        )<br>\n",
        "        print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcSFTkNbqKLt"
      },
      "source": [
        "Define batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN_Gs_iKqKLt"
      },
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x5LEjACqKLu"
      },
      "source": [
        "Create train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_hZS-r0qKLu"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images, train_padded_label, train_input_length, train_label_length)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXuaHl-9qKLv"
      },
      "source": [
        "Shuffle the dataset and batch it<br>\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)) \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ1H6_Z7qKLv"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.batch(batch_size) \\\n",
        "                             .prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RM3fO_XqKLv"
      },
      "source": [
        "Create validation dataset similarly without shuffling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RINlPqfqKLv"
      },
      "outputs": [],
      "source": [
        "valid_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (valid_images, valid_padded_label, valid_input_length, valid_label_length)\n",
        ").batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5sSXE3UqKLw"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam()\n",
        "best_val_loss = np.inf\n",
        "epochs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz0pkJsrqKLw"
      },
      "source": [
        "CTC loss function<br>\n",
        "def ctc_loss(y_true, y_pred, input_length, label_length):<br>\n",
        "    return tf.reduce_mean(<br>\n",
        "        tf.nn.ctc_loss(<br>\n",
        "            labels=y_true,<br>\n",
        "            logits=y_pred,<br>\n",
        "            label_length=label_length,<br>\n",
        "            logit_length=input_length,<br>\n",
        "            blank_index=-1,<br>\n",
        "            logits_time_major=False  # the output has shape (batch_size, time_steps, num_classes)<br>\n",
        "        )<br>\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk5Hd6gOqKLw"
      },
      "outputs": [],
      "source": [
        "def ctc_loss(y_true, y_pred, input_length, label_length):\n",
        "    \"\"\"\n",
        "    Custom CTC loss function using tf.keras.backend.ctc_batch_cost.\n",
        "\n",
        "    Args:\n",
        "        y_true: The true labels (sparse) with shape (batch_size, max_label_length).\n",
        "        y_pred: The predicted logits with shape (batch_size, max_time_steps, num_classes).\n",
        "        input_length: The lengths of the input sequences (logits).\n",
        "        label_length: The lengths of the true labels.\n",
        "\n",
        "    Returns:\n",
        "        Computed CTC loss for the batch.\n",
        "    \"\"\"\n",
        "    # Using Keras backend's ctc_batch_cost\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_k7erTMqKLx"
      },
      "source": [
        "Get the number of time steps (sequence length) after convolutions (31 in your case)<br>\n",
        "def get_time_steps(input_shape):<br>\n",
        "    return (input_shape[1] // 2) // 2  # Calculate based on pooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54EAIYenqKLx"
      },
      "source": [
        "time_steps = get_time_steps(train_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORtOOEAAqKLx"
      },
      "outputs": [],
      "source": [
        "time_steps = 31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwYQU-6SqKLx"
      },
      "outputs": [],
      "source": [
        "filepath=\"{}o-{}r-{}e-{}t-{}v.keras\".format(optimizer_name,\n",
        "                                          str(RECORDS_COUNT),\n",
        "                                          str(epochs),\n",
        "                                          str(train_images.shape[0]),\n",
        "                                          str(valid_images.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MD5KuDAqKLy"
      },
      "source": [
        "Loop through each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fylb6MCdqKLy"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    # Reset the metrics for each epoch\n",
        "    total_loss = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    # Create a progress bar for the training loop\n",
        "    train_pbar = tqdm(train_dataset, desc=f\"Training Epoch {epoch+1}/{epochs}\", total=len(train_images)//batch_size)\n",
        "\n",
        "    # Training loop\n",
        "    for batch, (batch_images, batch_padded_labels, batch_input_length, batch_label_length) in enumerate(train_pbar):\n",
        "        if batch_input_length.shape[0] != 8:\n",
        "            continue\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass (model's call method)\n",
        "            y_pred = model([batch_images], training=True)  # Pass only images to model\n",
        "\n",
        "            input_length_tensor = tf.reshape(batch_input_length, (8, 1))\n",
        "            label_length_tensor = tf.reshape(batch_label_length, (8, 1))\n",
        "\n",
        "            # Compute CTC loss\n",
        "            loss_value = ctc_loss(batch_padded_labels, y_pred, input_length_tensor, label_length_tensor)\n",
        "            # print('loss_value:', loss_value)\n",
        "\n",
        "        # Compute gradients\n",
        "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "        # Apply gradients (backpropagation)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # Accumulate the batch loss\n",
        "        total_loss += tf.reduce_sum(loss_value)\n",
        "        total_batches += 1\n",
        "\n",
        "        # Update progress bar with the current loss\n",
        "        train_pbar.set_postfix({'loss': (total_loss / total_batches).numpy()})\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    print(f\"Training Loss: {avg_loss.numpy()}\")\n",
        "    train_pbar.set_postfix({'training loss': avg_loss.numpy()})\n",
        "\n",
        "    # Validation loop\n",
        "    total_val_loss = 0.0\n",
        "    total_val_batches = 0\n",
        "\n",
        "    # Create a progress bar for the validation loop\n",
        "    valid_pbar = tqdm(valid_dataset, desc=f\"Validating Epoch {epoch+1}/{epochs}\", total=len(valid_images)//batch_size)\n",
        "\n",
        "    for batch, (batch_images, batch_padded_labels, batch_input_length, batch_label_length) in enumerate(valid_pbar):\n",
        "        if batch_input_length.shape[0] != 8:\n",
        "            continue\n",
        "        # Forward pass for validation\n",
        "        y_pred = model(batch_images, training=False)\n",
        "\n",
        "        input_length_tensor = tf.reshape(batch_input_length, (8, 1))\n",
        "        label_length_tensor = tf.reshape(batch_label_length, (8, 1))\n",
        "\n",
        "        # Compute CTC loss\n",
        "        val_loss_value = ctc_loss(batch_padded_labels, y_pred, input_length_tensor, label_length_tensor)\n",
        "\n",
        "        total_val_loss += tf.reduce_sum(val_loss_value)\n",
        "        total_val_batches += 1\n",
        "\n",
        "        # Update validation progress bar with current validation loss\n",
        "        valid_pbar.set_postfix({'val_loss': (total_val_loss / total_val_batches).numpy()})\n",
        "    avg_val_loss = total_val_loss / total_val_batches\n",
        "\n",
        "    train_pbar.set_postfix({'valid loss': avg_val_loss.numpy()})\n",
        "    # print(f\"Validation Loss: {avg_val_loss.numpy()}\")\n",
        "\n",
        "    # Checkpointing: Save the model if the validation loss improves\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        # print(\"Validation loss improved, saving the model...\")\n",
        "        best_val_loss = avg_val_loss\n",
        "        train_pbar.set_postfix({'best loss': avg_val_loss.numpy()})\n",
        "        model.save(filepath)\n",
        "    print(\"----- End of Epoch -----\")\n",
        "\n",
        "\n",
        "# Function to decode predictions and show accuracy after training\n",
        "def display_final_predictions(model, data, char_list, original_texts, num_samples=20):\n",
        "    print(\"\\nDisplaying final predictions on sample data:\")\n",
        "\n",
        "    # Extract data for the sample\n",
        "    sample_images, sample_padded_labels, sample_input_length, sample_label_length = data\n",
        "\n",
        "    # Make predictions on sample images\n",
        "    predictions = model.predict(sample_images[:num_samples])\n",
        "\n",
        "    # Decode the predictions using CTC\n",
        "    decoded = tf.keras.backend.ctc_decode(predictions,\n",
        "                           input_length=np.ones(predictions.shape[0]) * predictions.shape[1],\n",
        "                           greedy=True)[0][0]\n",
        "    out = tf.keras.backend.get_value(decoded)  # Get decoded outputs\n",
        "\n",
        "    # Compare predictions with ground truth\n",
        "    for i, x in enumerate(out[:num_samples]):\n",
        "        print(f\"Original text:  {original_texts[i]}\")\n",
        "        print(\"Predicted text: \", end='')\n",
        "\n",
        "        # Convert predicted indices to characters\n",
        "        for p in x:\n",
        "            if int(p) != -1:  # Ignore the blank index (-1)\n",
        "                print(char_list[int(p)], end='')\n",
        "        print()\n",
        "\n",
        "        # Display the corresponding image\n",
        "        plt.imshow(tf.reshape(sample_images[i], (32, 128)), cmap=plt.cm.gray)\n",
        "        plt.show()\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng28LUGnqKLy"
      },
      "source": [
        "Load a batch of data to test on after training is complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0f9ohijqKLz"
      },
      "outputs": [],
      "source": [
        "def get_test_data(dataset, num_samples=20):\n",
        "    # Fetch a small batch of validation data\n",
        "    test_batch = next(iter(dataset))\n",
        "    return test_batch[0][:num_samples], test_batch[1][:num_samples], test_batch[2][:num_samples], test_batch[3][:num_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nlax8csqKLz"
      },
      "source": [
        "After training, call this function<br>\n",
        "Assuming the model is already trained and `train_dataset`/`valid_dataset` is available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j38v4nkwqKLz"
      },
      "source": [
        "Get some sample data for testing (you can use validation dataset for this)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez1o8toEqKLz"
      },
      "outputs": [],
      "source": [
        "sample_images, sample_labels, sample_input_length, sample_label_length = get_test_data(valid_dataset, num_samples=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Bl11wMqKL0"
      },
      "source": [
        "Original texts corresponding to the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSkgO9F0qKL0"
      },
      "outputs": [],
      "source": [
        "test_original_texts = valid_original_text[:20]  # Adjust the indices based on your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWv9qLPBqKL0"
      },
      "source": [
        "Display predictions and accuracy after training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79dB13ayqKL1"
      },
      "outputs": [],
      "source": [
        "display_final_predictions(model=model,\n",
        "                          data=(sample_images, sample_labels, sample_input_length, sample_label_length),\n",
        "                          char_list=char_list,\n",
        "                          original_texts=test_original_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DG7KrDfqKL1"
      },
      "source": [
        "model.load_weights('adamo-10000r-5e-7850t-876v.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXYSDafjqKL1"
      },
      "source": [
        "image = cv2.imread(\"/Users/dima/Downloads/note_2_2024-13_47_18.png\", cv2.IMREAD_GRAYSCALE)<br>\n",
        "image = process_image(image)<br>\n",
        "image = image/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADNgDfJPqKL2"
      },
      "source": [
        "preds = model.predict(np.array([np.array([image]), the_labels, 1, label_length]).reshape(128, 32, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXu6xbzTqKL2"
      },
      "source": [
        "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgUBzjFvqKL2"
      },
      "outputs": [],
      "source": [
        "                                    # greedy=True)[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD-vf4LcqKL3"
      },
      "source": [
        "print(decoded)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}